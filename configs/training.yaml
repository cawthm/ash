# Training Configuration
# See SPECS.md Section 6 (Phase 5: Training Pipeline)

training:
  # Optimizer settings
  optimizer: adam
  learning_rate: 0.0001
  weight_decay: 0.01

  # Learning rate warmup
  warmup_steps: 1000

  # Gradient clipping
  max_grad_norm: 1.0

  # Batch size
  batch_size: 32

  # Maximum training epochs
  max_epochs: 100

  # Early stopping patience (validation loss)
  patience: 10

  # Mixed precision training
  fp16: true

# Data splits (chronological, no shuffling)
splits:
  train: 0.70
  validation: 0.15
  test: 0.15

  # Gap between splits to prevent lookahead bias (in seconds)
  gap_seconds: 3600

# Checkpointing
checkpointing:
  # Save frequency (in epochs)
  save_every: 1

  # Keep N best checkpoints
  keep_best: 3

  # Checkpoint directory
  checkpoint_dir: checkpoints/
