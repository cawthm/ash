"""Evaluation metrics and calibration analysis."""

from evaluation.metrics import (
    CalibrationResult,
    HorizonMetrics,
    MetricsConfig,
    MultiHorizonMetrics,
    PnLResult,
    brier_score,
    brier_score_per_bucket,
    compute_calibration,
    compute_horizon_metrics,
    compute_multi_horizon_metrics,
    directional_accuracy,
    entropy,
    expected_calibration_error,
    format_metrics_report,
    log_likelihood,
    mean_entropy,
    negative_log_likelihood,
    predicted_mean_bps,
    predicted_std_bps,
    sharpness,
    simulate_pnl,
)

__all__ = [
    "CalibrationResult",
    "HorizonMetrics",
    "MetricsConfig",
    "MultiHorizonMetrics",
    "PnLResult",
    "brier_score",
    "brier_score_per_bucket",
    "compute_calibration",
    "compute_horizon_metrics",
    "compute_multi_horizon_metrics",
    "directional_accuracy",
    "entropy",
    "expected_calibration_error",
    "format_metrics_report",
    "log_likelihood",
    "mean_entropy",
    "negative_log_likelihood",
    "predicted_mean_bps",
    "predicted_std_bps",
    "sharpness",
    "simulate_pnl",
]
