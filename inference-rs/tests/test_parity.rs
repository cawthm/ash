//! Feature parity tests between Python and Rust implementations.
//!
//! These tests load test vectors generated by Python (tests/feature_parity/generate_vectors.py)
//! and validate that Rust feature computation produces identical outputs.
//!
//! **Critical**: Any mismatch indicates train/serve skew risk and must be fixed.

use ash_inference::features::{
    compute_arrival_rate, compute_log_returns, compute_realized_volatility,
    compute_size_quantiles, compute_trade_imbalance, compute_vwap, compute_vwap_deviation,
    infer_trade_direction, PriceFeatureConfig,
};
use serde::{Deserialize, Serialize};
use std::path::PathBuf;

/// Test vector structure (matches Python generator output).
#[derive(Debug, Deserialize, Serialize)]
struct TestVectors {
    version: String,
    description: String,
    test_cases: Vec<TestCase>,
}

#[derive(Debug, Deserialize, Serialize)]
struct TestCase {
    name: String,
    description: String,
    inputs: serde_json::Value,
    expected: serde_json::Value,
}

/// Load test vectors from JSON file.
fn load_test_vectors() -> TestVectors {
    let test_vectors_path = PathBuf::from(env!("CARGO_MANIFEST_DIR"))
        .parent()
        .unwrap()
        .join("tests/feature_parity/test_vectors.json");

    let json_str = std::fs::read_to_string(&test_vectors_path)
        .unwrap_or_else(|_| panic!("Failed to read test vectors from {:?}", test_vectors_path));

    serde_json::from_str(&json_str).expect("Failed to parse test vectors JSON")
}

/// Parse array from JSON, converting null to NaN.
fn parse_array(value: &serde_json::Value) -> Vec<f64> {
    value
        .as_array()
        .expect("Expected array")
        .iter()
        .map(|v| {
            if v.is_null() {
                f64::NAN
            } else if let Some(s) = v.as_str() {
                match s {
                    "inf" => f64::INFINITY,
                    "-inf" => f64::NEG_INFINITY,
                    _ => panic!("Unexpected string value: {}", s),
                }
            } else {
                v.as_f64().expect("Expected number or null")
            }
        })
        .collect()
}

/// Compare two f64 values with NaN-aware equality.
fn assert_f64_eq(actual: f64, expected: f64, tolerance: f64, context: &str) {
    if expected.is_nan() {
        assert!(
            actual.is_nan(),
            "{}: Expected NaN, got {}",
            context,
            actual
        );
    } else if expected.is_infinite() {
        assert!(
            actual.is_infinite() && actual.signum() == expected.signum(),
            "{}: Expected {:?}, got {:?}",
            context,
            expected,
            actual
        );
    } else {
        let diff = (actual - expected).abs();
        assert!(
            diff <= tolerance,
            "{}: Expected {}, got {} (diff: {}, tolerance: {})",
            context,
            expected,
            actual,
            diff,
            tolerance
        );
    }
}

/// Compare two arrays with NaN-aware equality.
fn assert_arrays_eq(actual: &[f64], expected: &[f64], tolerance: f64, context: &str) {
    assert_eq!(
        actual.len(),
        expected.len(),
        "{}: Array length mismatch",
        context
    );

    for (i, (&a, &e)) in actual.iter().zip(expected.iter()).enumerate() {
        let element_context = format!("{}[{}]", context, i);
        assert_f64_eq(a, e, tolerance, &element_context);
    }
}

#[test]
fn test_parity_basic_log_returns() {
    let vectors = load_test_vectors();
    let test_case = vectors
        .test_cases
        .iter()
        .find(|tc| tc.name == "basic_log_returns")
        .expect("Test case 'basic_log_returns' not found");

    // Parse inputs
    let prices = parse_array(&test_case.inputs["prices"]);
    let windows = test_case.inputs["windows"]
        .as_array()
        .unwrap()
        .iter()
        .map(|v| v.as_u64().unwrap() as usize)
        .collect::<Vec<_>>();

    // Compute Rust outputs
    let returns_w1 = compute_log_returns(&prices, windows[0]).unwrap();
    let returns_w2 = compute_log_returns(&prices, windows[1]).unwrap();

    // Parse expected outputs
    let expected_w1 = parse_array(&test_case.expected["returns_window_1"]);
    let expected_w2 = parse_array(&test_case.expected["returns_window_2"]);

    // Validate
    const TOLERANCE: f64 = 1e-10;
    assert_arrays_eq(&returns_w1, &expected_w1, TOLERANCE, "returns_window_1");
    assert_arrays_eq(&returns_w2, &expected_w2, TOLERANCE, "returns_window_2");
}

#[test]
fn test_parity_vwap_calculation() {
    let vectors = load_test_vectors();
    let test_case = vectors
        .test_cases
        .iter()
        .find(|tc| tc.name == "vwap_calculation")
        .expect("Test case 'vwap_calculation' not found");

    // Parse inputs
    let prices = parse_array(&test_case.inputs["prices"]);
    let volumes = parse_array(&test_case.inputs["volumes"]);
    let window = test_case.inputs["window"].as_u64().unwrap() as usize;

    // Compute Rust outputs
    let vwap = compute_vwap(&prices, &volumes, window).unwrap();
    let vwap_dev = compute_vwap_deviation(&prices, &volumes, window).unwrap();

    // Parse expected outputs
    let expected_vwap = parse_array(&test_case.expected["vwap"]);
    let expected_dev = parse_array(&test_case.expected["vwap_deviation"]);

    // Validate
    const TOLERANCE: f64 = 1e-10;
    assert_arrays_eq(&vwap, &expected_vwap, TOLERANCE, "vwap");
    assert_arrays_eq(&vwap_dev, &expected_dev, TOLERANCE, "vwap_deviation");
}

#[test]
fn test_parity_realized_volatility() {
    let vectors = load_test_vectors();
    let test_case = vectors
        .test_cases
        .iter()
        .find(|tc| tc.name == "realized_volatility")
        .expect("Test case 'realized_volatility' not found");

    // Parse inputs
    let log_returns = parse_array(&test_case.inputs["log_returns"]);
    let windows = test_case.inputs["windows"]
        .as_array()
        .unwrap()
        .iter()
        .map(|v| v.as_u64().unwrap() as usize)
        .collect::<Vec<_>>();
    let annualization_factor = test_case.inputs["annualization_factor"].as_f64().unwrap();

    // Compute Rust outputs
    let rv_w10 =
        compute_realized_volatility(&log_returns, windows[0], annualization_factor).unwrap();
    let rv_w30 =
        compute_realized_volatility(&log_returns, windows[1], annualization_factor).unwrap();

    // Parse expected outputs
    let expected_w10 = parse_array(&test_case.expected["rv_window_10"]);
    let expected_w30 = parse_array(&test_case.expected["rv_window_30"]);

    // Validate - slightly higher tolerance for volatility due to sqrt operations
    const TOLERANCE: f64 = 1e-8;
    assert_arrays_eq(&rv_w10, &expected_w10, TOLERANCE, "rv_window_10");
    assert_arrays_eq(&rv_w30, &expected_w30, TOLERANCE, "rv_window_30");
}

#[test]
fn test_parity_zero_price_handling() {
    let vectors = load_test_vectors();
    let test_case = vectors
        .test_cases
        .iter()
        .find(|tc| tc.name == "zero_price_handling")
        .expect("Test case 'zero_price_handling' not found");

    // Parse inputs
    let prices = parse_array(&test_case.inputs["prices"]);
    let window = test_case.inputs["window"].as_u64().unwrap() as usize;

    // Compute Rust output
    let returns = compute_log_returns(&prices, window).unwrap();

    // Parse expected output
    let expected = parse_array(&test_case.expected["returns"]);

    // Validate
    const TOLERANCE: f64 = 1e-10;
    assert_arrays_eq(&returns, &expected, TOLERANCE, "zero_price_returns");
}

#[test]
fn test_parity_negative_price_handling() {
    let vectors = load_test_vectors();
    let test_case = vectors
        .test_cases
        .iter()
        .find(|tc| tc.name == "negative_price_handling")
        .expect("Test case 'negative_price_handling' not found");

    // Parse inputs
    let prices = parse_array(&test_case.inputs["prices"]);
    let window = test_case.inputs["window"].as_u64().unwrap() as usize;

    // Compute Rust output
    let returns = compute_log_returns(&prices, window).unwrap();

    // Parse expected output
    let expected = parse_array(&test_case.expected["returns"]);

    // Validate
    const TOLERANCE: f64 = 1e-10;
    assert_arrays_eq(&returns, &expected, TOLERANCE, "negative_price_returns");
}

#[test]
fn test_parity_insufficient_data() {
    let vectors = load_test_vectors();
    let test_case = vectors
        .test_cases
        .iter()
        .find(|tc| tc.name == "insufficient_data")
        .expect("Test case 'insufficient_data' not found");

    // Parse inputs
    let prices = parse_array(&test_case.inputs["prices"]);
    let window = test_case.inputs["window"].as_u64().unwrap() as usize;

    // Compute Rust output
    let returns = compute_log_returns(&prices, window).unwrap();

    // Parse expected output
    let expected = parse_array(&test_case.expected["returns"]);

    // Validate
    const TOLERANCE: f64 = 1e-10;
    assert_arrays_eq(&returns, &expected, TOLERANCE, "insufficient_data_returns");
}

#[test]
fn test_parity_realistic_price_movement() {
    let vectors = load_test_vectors();
    let test_case = vectors
        .test_cases
        .iter()
        .find(|tc| tc.name == "realistic_price_movement")
        .expect("Test case 'realistic_price_movement' not found");

    // Parse inputs
    let prices = parse_array(&test_case.inputs["prices"]);
    let volumes = parse_array(&test_case.inputs["volumes"]);
    let vwap_window = test_case.inputs["vwap_window"].as_u64().unwrap() as usize;
    let return_windows: Vec<u32> = test_case.inputs["return_windows"]
        .as_array()
        .unwrap()
        .iter()
        .map(|v| v.as_u64().unwrap() as u32)
        .collect();

    // Compute Rust outputs using individual functions
    // (Full compute_features equivalent would require combining multiple functions)
    let config = PriceFeatureConfig {
        return_windows,
        include_vwap: true,
        sample_interval: 1,
    };

    // Compute multi-window returns
    let returns_multi = ash_inference::features::compute_returns_multi_window(&prices, &config)
        .unwrap();

    // Compute VWAP deviation
    let vwap_dev = compute_vwap_deviation(&prices, &volumes, vwap_window).unwrap();

    // Parse expected outputs
    let expected_features = test_case.expected["features"]
        .as_array()
        .unwrap()
        .iter()
        .map(|row| parse_array(row))
        .collect::<Vec<_>>();

    let n_return_windows = config.return_windows.len();

    // Validate returns (columns 0 to n_return_windows-1)
    const TOLERANCE: f64 = 1e-10;
    for (window_idx, returns) in returns_multi.iter().enumerate() {
        for (time_idx, &actual) in returns.iter().enumerate() {
            let expected = expected_features[time_idx][window_idx];
            let context = format!("returns[t={}, w={}]", time_idx, window_idx);
            assert_f64_eq(actual, expected, TOLERANCE, &context);
        }
    }

    // Validate VWAP deviation (last column)
    for (time_idx, &actual) in vwap_dev.iter().enumerate() {
        let expected = expected_features[time_idx][n_return_windows];
        let context = format!("vwap_dev[t={}]", time_idx);
        assert_f64_eq(actual, expected, TOLERANCE, &context);
    }
}

#[test]
fn test_parity_orderflow_basic() {
    let vectors = load_test_vectors();
    let test_case = vectors
        .test_cases
        .iter()
        .find(|tc| tc.name == "orderflow_basic")
        .expect("Test case 'orderflow_basic' not found");

    // Parse inputs
    let prices = parse_array(&test_case.inputs["prices"]);
    let sizes = parse_array(&test_case.inputs["sizes"]);
    let timestamps = parse_array(&test_case.inputs["timestamps"]);
    let imbalance_window = test_case.inputs["imbalance_window"].as_u64().unwrap() as usize;
    let quantiles: Vec<f64> = test_case.inputs["quantiles"]
        .as_array()
        .unwrap()
        .iter()
        .map(|v| v.as_f64().unwrap())
        .collect();
    let arrival_rate_window = test_case.inputs["arrival_rate_window"].as_u64().unwrap() as usize;

    // Compute Rust outputs
    let directions = infer_trade_direction(&prices);
    let imbalance = compute_trade_imbalance(&directions, &sizes, imbalance_window).unwrap();
    let size_quants = compute_size_quantiles(&sizes, imbalance_window, &quantiles).unwrap();
    let arrival_rate = compute_arrival_rate(&timestamps, arrival_rate_window).unwrap();

    // Parse expected outputs
    let expected_directions: Vec<i8> = test_case.expected["directions"]
        .as_array()
        .unwrap()
        .iter()
        .map(|v| v.as_i64().unwrap() as i8)
        .collect();
    let expected_imbalance = parse_array(&test_case.expected["imbalance"]);
    let expected_q25 = parse_array(&test_case.expected["size_q25"]);
    let expected_q50 = parse_array(&test_case.expected["size_q50"]);
    let expected_q75 = parse_array(&test_case.expected["size_q75"]);
    let expected_arrival_rate = parse_array(&test_case.expected["arrival_rate"]);

    // Validate directions
    assert_eq!(
        directions, expected_directions,
        "Trade direction inference mismatch"
    );

    // Validate imbalance
    const TOLERANCE: f64 = 1e-10;
    assert_arrays_eq(&imbalance, &expected_imbalance, TOLERANCE, "imbalance");

    // Validate size quantiles
    let q25: Vec<f64> = size_quants.iter().map(|row| row[0]).collect();
    let q50: Vec<f64> = size_quants.iter().map(|row| row[1]).collect();
    let q75: Vec<f64> = size_quants.iter().map(|row| row[2]).collect();
    assert_arrays_eq(&q25, &expected_q25, TOLERANCE, "size_q25");
    assert_arrays_eq(&q50, &expected_q50, TOLERANCE, "size_q50");
    assert_arrays_eq(&q75, &expected_q75, TOLERANCE, "size_q75");

    // Validate arrival rate
    assert_arrays_eq(
        &arrival_rate,
        &expected_arrival_rate,
        TOLERANCE,
        "arrival_rate",
    );
}

#[test]
fn test_parity_orderflow_zero_ticks() {
    let vectors = load_test_vectors();
    let test_case = vectors
        .test_cases
        .iter()
        .find(|tc| tc.name == "orderflow_zero_ticks")
        .expect("Test case 'orderflow_zero_ticks' not found");

    // Parse inputs
    let prices = parse_array(&test_case.inputs["prices"]);
    let sizes = parse_array(&test_case.inputs["sizes"]);
    let window = test_case.inputs["window"].as_u64().unwrap() as usize;

    // Compute Rust outputs
    let directions = infer_trade_direction(&prices);
    let imbalance = compute_trade_imbalance(&directions, &sizes, window).unwrap();

    // Parse expected outputs
    let expected_directions: Vec<i8> = test_case.expected["directions"]
        .as_array()
        .unwrap()
        .iter()
        .map(|v| v.as_i64().unwrap() as i8)
        .collect();
    let expected_imbalance = parse_array(&test_case.expected["imbalance"]);

    // Validate
    assert_eq!(
        directions, expected_directions,
        "Trade direction with zero ticks mismatch"
    );

    const TOLERANCE: f64 = 1e-10;
    assert_arrays_eq(&imbalance, &expected_imbalance, TOLERANCE, "imbalance");
}

#[test]
fn test_parity_orderflow_realistic() {
    let vectors = load_test_vectors();
    let test_case = vectors
        .test_cases
        .iter()
        .find(|tc| tc.name == "orderflow_realistic")
        .expect("Test case 'orderflow_realistic' not found");

    // Parse inputs
    let prices = parse_array(&test_case.inputs["prices"]);
    let sizes = parse_array(&test_case.inputs["sizes"]);
    let timestamps = parse_array(&test_case.inputs["timestamps"]);
    let imbalance_window = test_case.inputs["imbalance_window"].as_u64().unwrap() as usize;
    let quantiles: Vec<f64> = test_case.inputs["quantiles"]
        .as_array()
        .unwrap()
        .iter()
        .map(|v| v.as_f64().unwrap())
        .collect();
    let arrival_rate_window = test_case.inputs["arrival_rate_window"].as_u64().unwrap() as usize;

    // Compute Rust outputs
    let directions = infer_trade_direction(&prices);
    let imbalance = compute_trade_imbalance(&directions, &sizes, imbalance_window).unwrap();
    let size_quants = compute_size_quantiles(&sizes, imbalance_window, &quantiles).unwrap();
    let arrival_rate = compute_arrival_rate(&timestamps, arrival_rate_window).unwrap();

    // Parse expected outputs from features array
    let expected_features = test_case.expected["features"]
        .as_array()
        .unwrap()
        .iter()
        .map(|row| parse_array(row))
        .collect::<Vec<_>>();

    // Expected features order: [imbalance, size_q25, size_q50, size_q75, arrival_rate]
    let expected_imbalance: Vec<f64> = expected_features.iter().map(|row| row[0]).collect();
    let expected_q25: Vec<f64> = expected_features.iter().map(|row| row[1]).collect();
    let expected_q50: Vec<f64> = expected_features.iter().map(|row| row[2]).collect();
    let expected_q75: Vec<f64> = expected_features.iter().map(|row| row[3]).collect();
    let expected_arrival_rate: Vec<f64> = expected_features.iter().map(|row| row[4]).collect();

    // Validate
    const TOLERANCE: f64 = 1e-10;
    assert_arrays_eq(&imbalance, &expected_imbalance, TOLERANCE, "imbalance");

    let q25: Vec<f64> = size_quants.iter().map(|row| row[0]).collect();
    let q50: Vec<f64> = size_quants.iter().map(|row| row[1]).collect();
    let q75: Vec<f64> = size_quants.iter().map(|row| row[2]).collect();
    assert_arrays_eq(&q25, &expected_q25, TOLERANCE, "size_q25");
    assert_arrays_eq(&q50, &expected_q50, TOLERANCE, "size_q50");
    assert_arrays_eq(&q75, &expected_q75, TOLERANCE, "size_q75");

    assert_arrays_eq(
        &arrival_rate,
        &expected_arrival_rate,
        TOLERANCE,
        "arrival_rate",
    );
}
